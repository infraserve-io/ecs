{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"About","text":"<p>Enterprise Configuration Service (ECS) is a brand new way to inject configuration into your pipelines. It aims to bring configuration under control and encourages you to keep it DRY (Don't Repeat Yourself). </p> <p>With ECS, instead of pipeline variables being scattered around the organizations estate in various repositories, it's stored in one or more centralized repositories. Using ECS it's still possible to split configuration in logical ways, but it's a choice rather than being forced through tooling limitations. </p> <p>A primary goal of ECS is to keep logic out of configuration in order to make it readable by anyone. When you start embedding merge logic into config it loses clarity and it takes a programmers mindset in order to understand what it does. With ECS, all config is defined in clean YAML files that anyone can comprehend. </p> <p>ECS uses artificial intelligence (CTO AI) to generate validation schemas for your production configurations. Creating schemas for validation is often an after thought, but with ECS we make it very easy, just type <code>cto ecs config schema \u2013write</code> and a schema that matches your tested config output will be generated, that\u2019s all there is to it. </p>"},{"location":"#architecture","title":"Architecture","text":"<p>ECS is based on a central server, one per Git based configuration store. A small to medium sized organization only requires one configuration as it is divided up by it's hierachical nature. Your configuration can have multiple roots and can support any layout. If an organization requires it however, multiple servers can be setup to split config repositories. This would typically be required if it is necessary to split up user admin responsibilites. </p> <p></p> <p>Users and pipelines interact with the configuration via the ECS CLI. Read about the CLI here.</p>"},{"location":"#ecs-cloud","title":"ECS Cloud","text":"<p>ECS Cloud offers a very fast way to get up and running with centralized configuration. All you need is a Git repository that can be accessed via the Internet (we can provide you with an IP whitelist so you can lock access down to ECS Cloud) and an encryption key in AWS, GCP or Azure. You can even use an ECS Cloud created encryption key if you just want to get a feel for ECS, then recreate your configuration with a new key when you are ready to get serious about centralized config. </p> <p>See how to get started with ECS Cloud here. </p> <p>A 14 day free trial is available and you could be up and running with an environment that you can take to production within 5 minutes.</p>"},{"location":"#ecs-on-premise","title":"ECS On-Premise","text":"<p>ECS can be installed on-premise using any Docker host such as AWS ECS, EKS or Azure AKS or Google GKE. ECS On-Premise is especially useful where you have a self hosted Git server that can't be accessed from the Internet. See how to get started with ECS on-premise here. </p> <p>Even better, you can start with ECS Cloud and then when you have got the feel for ECS, you can simply setup ECS On-Premise, using same repository and encryption key as you had configured in ECS Cloud, and the migration to on-premise is complete!</p> <p>A 14 day free trial is available and similarly to ECS Cloud, if you have Docker installed locally you could be up and running with an environment to learn within 10 minutes.</p>"},{"location":"#ecs-features","title":"ECS Features","text":"<p>ECS embodies some powerful concepts such as:</p> <ul> <li>Hierarchical Datastore <ul> <li>Datastore can be structured however it needs to be to represent your organizations needs</li> <li>Project teams all have their own private area in which they can manage their config</li> <li>The datastore can comprise of a mix of YAML, JSON and Apple Pkl meaning each project can use it's preferred configuration language</li> <li>ECS layers functionality on top of Pkl such as output schema validation, webhooks, policy as code</li> </ul> </li> <li>DRY Config<ul> <li>Powerful and configurable YAML/ JSON mergers that promotes the idea of DRY (Don't Repeat Yourself) configuration</li> </ul> </li> <li>Output Formats <ul> <li>Outputs specific parts of config to pipelines in various formats including YAML, JSON, .env and .ini. These formats make ECS compatible with AWS Cloudformation, Terraform, Kubernates and more. </li> </ul> </li> <li>Secret Encryption<ul> <li>Uses Mozilla SOPS under the covers but with a difference, end users and pipelines don't need access to encryption keys. The ECS server handles secret encryption which enables users to safely store secrets in your config repository, yes, in Git!</li> </ul> </li> <li>Git Based Database <ul> <li>The ECS server communicates with a central repository that you provide. This repository tracks all changes and maintains audit records and rollback capability</li> <li>Users do not interact with the central repository thus enabling user access control<ul> <li>Without this, using a Git based approach for the configuration database, as all configuration management solutions should, all users would need access to the entire configuration</li> </ul> </li> <li>Users can be given read access to the Git repository so they can safely access the entire configuration landscape via the Git UI, but, they don't need it</li> </ul> </li> <li>Config Versioning<ul> <li>Pipelines can be fixed to a certain version and new configs can be released in a controlled manor</li> </ul> </li> <li>AI Generated Schema Validation<ul> <li>All config is tested for validity before it is loaded into the Git database so errors must be resolved before config is stored</li> <li>Use AI to build a schema using the rich functionality of JSON Schema and any mismatches will be reported and will block builds thereby increasing reliability and consistency in deployments. AI will build a schema that exactly matches your output, giving you assurance your pipeline will fail if the build config is invalid</li> </ul> </li> <li>Drift Detection<ul> <li>Optional block on pipelines that are running on outdated config. Pipelines running on a fixed version of config can be configured to fail if there is a new version of config available. </li> </ul> </li> <li>Multi User CLI<ul> <li>Admin level users manage users access and merge strategies</li> <li>User level users can be granted readonly or read/write to specific areas of the config hierarchy</li> <li>Service accounts are used by pipelines to consume areas of config they should be granted access to</li> </ul> </li> <li>Webhook Support (coming soon) <ul> <li>Change something in the config and configured webhooks can be fired to trigger pipelines</li> </ul> </li> <li>AI Generated Policy as Code (coming soon) <ul> <li>With policy as code written in Rego, it is possible to control what users can enter into configuration, such as blocking expensive instance types or admin roles in IAM policies anywhere other than in root level IAM definitions. Rego policies take a while to get used to, our AI makes it easy</li> </ul> </li> </ul>"},{"location":"#example-of-non-dry-configuration-storage","title":"Example of Non-DRY Configuration Storage","text":"<p>Most organizations store configurations in application/ user specific repositories and think they are DRY because they modularize the pipeline code, but the configuration for the pipeline is rarely DRY. See this example for deploying 2 separate AWS EC2 instances for 2 users:</p> <p>This code is DRY, the module can be reused, all good so far.</p> <p></p> <p>Now we will deploy this for a user, all we need to do is create .tfvars and run Terraform.</p> <p>User 1 configuration:  </p> <p>Now user 2 needs an EC2 as well, they want exactly the same config other than user 2's VPC settings are different, no problem, copy user 1's config, change the VPC setting and run Terraform, all good.</p> <p></p> <p>Wrong! This is what we see all the time, duplication is rife. In this scenario it's not too bad as there are not many variables and there are only 2 sets of config, but complex modules with many variables, multiplied by many users and it becomes really hard to manage, and upgrading a module is really hard as all the .tfvars files need to be modified to suit new module requirements. </p>"},{"location":"#example-of-dry-configuration-storage","title":"Example of DRY Configuration Storage","text":"<p>With ECS this is so much cleaner. First we define what is common for most users of the module:</p> <p></p> <p>Then for the individual user config we only need to override the VPC name</p> <p></p> <p>Imagine this at scale where configuration is stored centrally for many pipelines, your entire infrastructure can be described this way instead of with individual stores of pipeline variables. </p>"},{"location":"#pipeline-integration","title":"Pipeline Integration","text":"<p>What's even better is that ECS just emits the merged variables into your pipelines so they work exactly as they did before, no code changes needed other than to call ECS before running Terraform.</p> <p>Here is an example of a simple Jenkinsfile that will generate the configuration for an EC2 based on a parameter.</p> <p></p> <p>This is just the beginning of how ECS can refine your configuration storage, read on to find out it's other features.</p>"},{"location":"#where-next","title":"Where Next?","text":"<p>Getting started with ECS is very easy, just follow the instructions here.</p>"},{"location":"build_strategies/","title":"Configuration Build Strategies","text":"<p>Build strategies are used to configure how configuration is compiled for use in pipelines. </p>"},{"location":"build_strategies/#background","title":"Background","text":"<p>When ECS config is written in YAML or JSON, the strategy language can be used to merge config objects in meaningful ways. It is a powerful feature that is the basis of how ECS promotes DRY configuration. </p>"},{"location":"build_strategies/#how-does-it-work","title":"How Does it Work","text":"<p>When the config is built/ compiled using the <code>cto ecs config build</code> command, a base directory is specified using <code>--path</code> parameter. All the files under this path are recursively loaded into a set of dictionaries. Using a set of declarative constructs that are written in a <code>__strategies.yaml</code> file, the strategy language gives you control over how these dictionaries are merged to produce the final output. </p>"},{"location":"build_strategies/#merging","title":"Merging","text":"<p>An example dictionary is shown below, treat this as configuration that is common to all of a certain area of config and it might live in a file in a directory somewhere in your config called <code>common</code>:</p> <pre><code>{\n    \"vpc\": \"vpc-common\",\n    \"s3-encryption\": true\n}\n</code></pre> <p>A second dictionary lives in a file in an account specific area of the config hierarchy. <pre><code>{\n    \"vpc\": \"vpc-account-specific-override\",\n}\n</code></pre></p> <p>When these 2 dictionaries are merged using common as the base, the result is the following dictionary:</p> <pre><code>{\n    \"vpc\": \"vpc-account-specific-override\",\n    \"s3-encryption\": true\n}\n</code></pre> <p>It can be seen that the common values with no matching keys in the account specific file are preserved, whilst the keys that match are overwritten. </p>"},{"location":"build_strategies/#iterators","title":"Iterators","text":"<p>Iterators allow the loaded dictionaries to be traversed and merged as above, with certain manipulations being possible such as injecting additional parent keys. We'll use the following dictionary to explain how iterators can be used:</p> <pre><code>{\n    \"key-1\": \"value-1\",\n    \"key-2\": \"value-2\",\n    \"key-3\": \"value-3\"\n}\n</code></pre> <p>To traverse the dictionary above, we define an iterator using <code>for_each</code> and use <code>each_key</code> to access the keys and <code>each_value</code> to access the values. The values would typically be object structures as defined in your config hierarchy such as the following:</p>"},{"location":"build_strategies/#permissions","title":"Permissions","text":"<p>Build strategies can be managed by admin users and users that were created or edited with the <code>--edit-stratgies</code> flag. To remove the ability for a user to change strategies, use <code>cto ecs users edit --no-edit-strategies</code>.</p>"},{"location":"build_strategies/#__strategyyaml-files","title":"__strategy.yaml files","text":"<p>These files contain the logic for config compilation. You can learn how to use the strategy language by following config examples and by reading the strategy language reference</p> <p>Strategy files can exist in 2 distinct areas of config, either in the path of the config they are intended to operate with, or in the root of the config where they can be written once by an ECS admin and consumed by any user within the context of paths to which they have access.</p>"},{"location":"build_strategies/#path-specific-strategies","title":"Path Specific Strategies","text":"<p>Strategies can be created and managed by users to suit their needs. Of course, the user has to have access to the particular path, meaning they can't change strategies they are not authorized to access. Users also need to have the <code>--edit-strategies</code> flag set to true in order to change strategies files. </p> <p>Path based strategies need to exist in the path specified in the <code>cto ecs config build --path &lt;path&gt;</code> command.</p> <p>Paths inside the <code>__strategies.yaml</code> file are specified relative to the path of the file and can be relative upwards in the directory structure (../../), providing the user has access to the specified path. </p>"},{"location":"build_strategies/#where-next","title":"Where Next?","text":"<p>Check out the strategy reference here</p>"},{"location":"build_strategies/index%20copy/","title":"Configuration Build Strategies","text":"<p>Build strategies are used to configure how configuration is compiled for use in pipelines. </p>"},{"location":"build_strategies/index%20copy/#examples","title":"Examples","text":"<p>Let's get started with some examples. Note, in these configuration examples, the file names are not taken into consideration, the only thing the config compiler cares about is file content, the object structure contained is what is merged, not the file names.</p>"},{"location":"build_strategies/index%20copy/#default-build-strategies","title":"Default Build Strategies","text":"<p>ECS ships with 2 simple inbuilt build strategies and others that configuring as they are dependent on your config diretory structure. Let's dig into the default strategies first. </p>"},{"location":"build_strategies/index%20copy/#emit-path","title":"Emit Path","text":"<p>Emit path strategy simply emits the YAML config for the path specified.</p>"},{"location":"build_strategies/index%20copy/#config","title":"Config","text":"<p><code>ec2.yaml</code> <pre><code>ec2:\n    disk_size: 400\n</code></pre> buckets.yaml <pre><code>s3:\n    encrypted: true\n</code></pre></p>"},{"location":"build_strategies/index%20copy/#command","title":"Command","text":"<p><code>cto ecs config build --path &lt;path to file or directory&gt; --format yaml</code></p>"},{"location":"build_strategies/index%20copy/#output","title":"Output","text":"<pre><code>ec2:\n    disk_size: 400\ns3:\n    encrypted: true\n</code></pre>"},{"location":"build_strategies/index%20copy/#merge-path-and-subdirectories","title":"Merge Path and Subdirectories","text":"<p>Emit path and subdirectories strategy emits the YAML config for the path specified.</p>"},{"location":"build_strategies/index%20copy/#directory-tree","title":"Directory Tree","text":"<pre><code>-teams  \n  -ec2.yaml  \n  -team-1  \n    -ec2.yaml  \n</code></pre>"},{"location":"build_strategies/index%20copy/#config_1","title":"Config","text":"<p><code>teams/ec2.yaml</code> <pre><code>ec2:\n    instance_type: small\n    disk_size: 400\n</code></pre></p> <p><code>teams/team-1/ec2.yaml</code> <pre><code>ec2:\n    disk_size: 600\n</code></pre></p>"},{"location":"build_strategies/index%20copy/#command_1","title":"Command","text":"<p><code>cto ecs config build --path teams --recursive --format yaml</code></p>"},{"location":"build_strategies/index%20copy/#output_1","title":"Output","text":"<pre><code>ec2:\n    instance_type: small\n    disk_size: 600\n</code></pre>"},{"location":"build_strategies/index%20copy/#custom-build-strategies","title":"Custom Build Strategies","text":"<p>In some cases ECS can't know what you want to do as after all, you can define any structure you like for your configuration. For these more complex build strategies you need to provide metadata to the config compiler so that it knows which directories to merge with which and in what order. Let's look at some examples of these strategies.</p>"},{"location":"build_strategies/index%20copy/#merge-common-data-into-a-multi-directory-config-structure","title":"Merge Common Data into a Multi Directory Config Structure","text":"<p>This is where ECS shines and facilitates your config to become DRY (Do Not Repeat Yourself).</p> <p>Here we'll show you how to create a set of configuration files in a common directory and merge a separate multi directory structure over the top of the common thus allowing parameter overrides and additions according to pipeline needs.</p> <p>In order to differentiate the distinct subdirectories into separate configurations we use a strategy type of <code>data_with_key_from_path</code>. This is a very useful and popular strategy.  </p>"},{"location":"build_strategies/index%20copy/#directory-tree_1","title":"Directory Tree","text":"<pre><code>-common  \n  -ec2.yaml  \n  -object_storage.yaml\n-teams  \n  -__strategies.yaml\n  -teams  \n    -team-1  \n      -ec2.yaml  \n      -object_storage.yaml\n    -team-2  \n      -ec2.yaml  \n      -object_storage.yaml\n</code></pre>"},{"location":"build_strategies/index%20copy/#config_2","title":"Config","text":"<p><code>common/ec2.yaml</code> <pre><code>ec2:\n  instance_type    : t2.medium\n  user_data        : null\n  ami              : ami-1234567890\n  instance_profile : instance-profile-1\n  disk_size        : 200\n  vpc_name         : default\n  tags:\n    terraform : true\n</code></pre></p> <p><code>common/object_storage.yaml</code> <pre><code>s3:\n    versioning: true\n    encryption: true\n    tags:\n        terraform : true\n</code></pre></p> <p><code>teams/team-1/ec2.yaml</code> <pre><code>ec2:\n    instance_type: t3.large\n</code></pre></p> <p><code>teams/team-1/object_storage.yaml</code> <pre><code>s3:\n    bucket_name: team-1-bucket\n</code></pre></p> <p><code>teams/teams/team-2/ec2.yaml</code> <pre><code>ec2:\n    instance_type: c5.xlarge\n</code></pre></p> <p><code>teams/team-1/object_storage.yaml</code> <pre><code>s3:\n    bucket_name: team-2-bucket\n</code></pre></p>"},{"location":"build_strategies/index%20copy/#command_2","title":"Command","text":"<p><code>cto ecs config build --path teams --strategy merge_common_to_teams --format yaml</code></p>"},{"location":"build_strategies/index%20copy/#output_2","title":"Output","text":"<pre><code>team-1:                                                                       \n  ec2:                                                                        \n    ami: ami-1234567890                                                       \n    disk_size: 200                                                            \n    instance_profile: instance-profile-1                                      \n    instance_type: t3.large                                                   \n    tags:                                                                     \n      terraform: true                                                         \n    user_data: null                                                           \n    vpc_name: default                                                         \n  s3:\n    versioning: true\n    encryption: true\n    tags:\n        terraform : true\n    bucket_name: team-1-bucket\nteam-2:                                                                       \n  ec2:                                                                        \n    ami: ami-1234567890                                                       \n    disk_size: 200                                                            \n    instance_profile: instance-profile-1                                      \n    instance_type: c5.xlarge                                                  \n    tags:                                                                     \n      terraform: true                                                         \n    user_data: null                                                           \n    vpc_name: default \n  s3:\n    versioning: true\n    encryption: true\n    tags:\n        terraform : true\n    bucket_name: team-2-bucket\n</code></pre> <p>Note how the directory names have been added as keys in the emitted structure. This allows you to pick the config for any team, and the only configuration that was specified for the specific team was the <code>instance_type</code> and <code>bucket_name</code>.</p> <p>To cut the config down to the specific part required for a pipeline, use the <code>--filter</code> parameter on the build command, see example below:</p>"},{"location":"build_strategies/index%20copy/#strategy-definition","title":"Strategy Definition","text":"<p>In order to accomplish this output it is necessary to tell the config compiler what directories to work with and in what order. This is done by creating a metadata file called <code>__strategies.yaml</code> in the locatiom you wish to use as the root of the build. As you will note in the directory tree depicted above, this file is defined in the <code>teams</code> directory, the same directory specified in the <code>--path</code> parameter that was passed to <code>cto ecs config build</code>. Also note, the relative path to the common directory. ECS build strategies can access any directory below where they are placed. </p> <p><code>./teams/__strategies.yaml</code> <pre><code>strategies:\n  merge_common_to_teams:\n    operations:\n      - for_each:\n          iterator: $team_data\n          action:\n            inject:\n              - $common\n              - $each\n    variable_definitions:\n      common:\n        path: ./common\n        type: data\n      team_data:\n        path: ./teams/{team}\n        type: data_with_key_from_path\n</code></pre></p> <p>This file can contain multiple strategies for specific operations on your underlaying structure. In this case we have only one strategy called <code>merge_common_with_teams</code>.</p> <p>Let's see how to use this strategy. We'll use the <code>--filter</code> parameter to extract the area of config we are interested in. </p> <p><code>cto ecs config build --path teams --strategy merge_common_to_teams --format yaml --filter '\"team-1\".s3</code></p>"},{"location":"build_strategies/index%20copy/#output_3","title":"Output","text":"<pre><code>team-1:                                                                       \n  s3:\n    versioning: true\n    encryption: true\n    tags:\n        terraform : true\n    bucket_name: team-1-bucket\n</code></pre>"},{"location":"build_strategies/index%20copy/#multiple-directory-common","title":"Multiple Directory Common","text":"<p>It is possible to specify more directories whose contents will be merged in as necessary. Note the order below, <code>./common</code> is read in first, then <code>./override_common</code> is merged over the top, lastly the individual teams are merged over the top by using the <code>for_each</code> construct. </p> <p><code>./teams/__strategies.yaml</code> <pre><code>strategies:\n  merge_common_and_override_to_teams:\n    operations:\n      - for_each:\n          iterator: $team_data\n          action:\n            inject:\n              - $common\n              - $override_common\n              - $each\n    variable_definitions:\n      common:\n        path: ./common\n        type: data\n      override_common:\n        path: ./override_common\n        type: data\n      team_data:\n        path: ./teams/{team}\n        type: data_with_key_from_path\n</code></pre></p>"},{"location":"build_strategies/index%20copy/#layer-common-data-into-a-multi-directory-config-structure","title":"Layer Common Data into a Multi Directory Config Structure","text":"<p>The compiler allows us to pick certain objects and dynamically merge them into destination objects. Let's modify our <code>common/ec2.yaml</code> and add some different configuration types. We'll use the base config, layer over the particular ec2 type, and then override with the specific teams config.</p> <p><code>common/ec2.yaml</code> <pre><code>ec2:\n  instance_type    : t2.medium\n  user_data        : null\n  ami              : ami-1234567890\n  instance_profile : instance-profile-1\n  disk_size        : 200\n  vpc_name         : default\n  tags:\n    terraform : true\n\nec2-base:\n  instance_type    : t2.medium\n  user_data        : null\n  ami              : ami-1234567890\n  instance_profile : instance-profile-1\n  disk_size        : 200\n  vpc_name         : default\n  tags:\n    terraform : true\n\nec2-select-type:\n    standard:\n        instance_type: t3.large\n        disk_size: 1000\n    developer:\n        instance_type: c5.2xlarge\n        disk_size: 3000\n</code></pre></p> <p><code>./teams/__strategies.yaml</code> <pre><code>strategies:\n  standard-ec2:\n    operations:\n      - for_each:\n          iterator: $team_data\n          action:\n            inject:\n              - $base\n              - $selected_type\n              - $each\n    variable_definitions:\n      team_data:\n        path: ./teams/{team}\n        type: data_with_key_from_path\n      base:\n        path: ./common/ec2.yaml\n        type: data_with_key_from_object_field\n        source_object_path: ec2-base\n        destination_object_path: ec2\n      selected_type:\n        path: ./common/ec2.yaml\n        type: data_with_key_from_object_field\n        source_object_path: ec2-select-type.standard\n        destination_object_path: ec2\n\n  developer-ec2:\n    operations:\n      - for_each:\n          iterator: $team_data\n          action:\n            inject:\n              - $base\n              - $selected_type\n              - $each\n    variable_definitions:\n      team_data:\n        path: ./teams/{team}\n        type: data_with_key_from_path\n      base:\n        path: ./common/ec2.yaml\n        type: data_with_key_from_object_field\n        source_object_path: ec2-base\n        destination_object_path: ec2\n      selected_type:\n        path: ./common/ec2.yaml\n        type: data_with_key_from_object_field\n        source_object_path: ec2-select-type.developer\n        destination_object_path: ec2\n</code></pre></p> <p>In the example strategies above, <code>standard-ec2</code> is going to first load <code>ec2-base</code> object from common, then it will overlay <code>ec2-select-type.standard</code>, then the team specific config.</p> <p><code>cto ecs config build --path \"/teams\" --strategy-name standard-ec2</code> config with <code>instance_type</code> of <code>t3-large</code> for <code>team-1</code> and <code>c5.xlarge</code> for <code>team-2</code> as for that team it's overriden.</p>"},{"location":"build_strategies/index%20copy/#output_4","title":"Output","text":"<pre><code>team-1:                \n  ec2:\n    ami: ami-1234567890\n    disk_size: 1000    \n    instance_profile: instance-profile-1                                                                                                                \n    instance_type: t3.large \n    tags:              \n      terraform: true  \n    user_data: null    \n    vpc_name: default  \nteam-2:                \n  ec2:                 \n    ami: ami-1234567890\n    disk_size: 1000    \n    instance_profile: instance-profile-1                                                                                                                \n    instance_type: c5.xlarge\n    tags:              \n      terraform: true  \n    user_data: null    \n    vpc_name: default\n</code></pre> <p><code>cto ecs config build --path \"/teams\" --strategy-name developer-ec2</code> config with <code>instance_type</code> of <code>c5.2xlarge</code> for <code>team-1</code> and <code>c5.xlarge</code> for <code>team-2</code> as for that team it's overriden.</p>"},{"location":"build_strategies/index%20copy/#output_5","title":"Output","text":"<pre><code>team-1:                \n  ec2:\n    ami: ami-1234567890\n    disk_size: 3000    \n    instance_profile: instance-profile-1                                                                                                                \n    instance_type: c5.2xlarge \n    tags:              \n      terraform: true  \n    user_data: null    \n    vpc_name: default  \nteam-2:                \n  ec2:                 \n    ami: ami-1234567890\n    disk_size: 3000    \n    instance_profile: instance-profile-1                                                                                                                \n    instance_type: c5.xlarge\n    tags:              \n      terraform: true  \n    user_data: null    \n    vpc_name: default\n</code></pre>"},{"location":"build_strategies/index%20copy/#dynamic-config-data-creation-using-data-injection","title":"Dynamic Config Data Creation Using Data Injection","text":"<p>The above config is great and gets us closer to DRY, but when we want to create multiple of some resource (imagine a Terraform for_each iterating over a list of instances to create), possibly with different configurations, we don't want to have to repeat the config for each resource. We need a way to specify a resource name/ ID and have config injected into it with overrides being possible.</p>"},{"location":"build_strategies/index%20copy/#directory-tree_2","title":"Directory Tree","text":"<pre><code>-common  \n  -ec2.yaml  \n-teams  \n  -__strategies.yaml\n  -teams  \n    -team-1  \n      -ec2s.yaml  \n    -team-2  \n      -ec2s.yaml  \n</code></pre>"},{"location":"build_strategies/index%20copy/#config_3","title":"Config","text":"<p><code>common/ec2.yaml</code> <pre><code>ec2:\n  instance_type    : t2.medium\n  user_data        : null\n  ami              : ami-1234567890\n  instance_profile : instance-profile-1\n  disk_size        : 200\n  vpc_name         : default\n  tags:\n    terraform : true\n</code></pre></p> <p><code>teams/team-1/ec2s.yaml</code> <pre><code>ec2:\n    ec2-instance-1: {}\n    ec2-instance-2:\n        instance_type: t3.medium\n    ec2-instance-3:\n        instance_type: t3.large\n    ec2-instance-4:\n        instance_type: c5.2xlarge\n</code></pre></p> <p><code>teams/team-2/ec2s.yaml</code> <pre><code>ec2:\n    ec2-instance-1:\n        disk_size: 10000\n    ec2-instance-2:\n        instance_type: c5.4xlarge\n        disk_size: 20000\n</code></pre></p> <p><code>./__strategies.yaml</code> <pre><code>strategies:\n  resource_per_team:\n    operations:\n      - for_each:\n          iterator: $team_data\n          actions:\n            - for_each:\n                iterator: $team_data.$each_key.ec2\n                actions:\n                  - inject:\n                      - $base\n                      - $each_value\n            - add_parent: ec2\n    variable_definitions:\n      base:\n        path: ${config_path}/common/ec2.yaml\n        type: data_with_key_from_object_field\n        source_object_path: ec2-base\n        destination_object_path: ''\n      team_data:\n        path: ${config_path}/teams/{team}\n        type: data_with_key_from_path\n</code></pre></p>"},{"location":"build_strategies/reference/","title":"Strategy syntax reference","text":""},{"location":"build_strategies/reference/#operations","title":"Operations","text":""},{"location":"build_strategies/reference/#inject","title":"inject","text":"<p><code>inject</code> reads data specified as a string variable and adds its content to the main object.</p> <pre><code>inject:\n  - $common\n  - team_data\n</code></pre> <p>Let's assume the variables have the following values:</p> <pre><code>common:\n  content:\n    common_var: common_test\nteam_data:\n  content:\n    var: team1\n</code></pre> <p>The result:</p> <pre><code>content:\n    common_var: common_test\n    var: team1\n</code></pre> <p>The inject operation supports object key unpacking using the dot notation.  </p> <p>To unpack the <code>content</code> key from example above:</p> <pre><code>inject:\n  - team_data.content\n</code></pre> <p>The result:</p> <pre><code>var: team1\n</code></pre>"},{"location":"build_strategies/reference/#add_parent","title":"add_parent","text":"<p><code>add_parent</code> modifies the current object by adding a parent object.</p> <pre><code>inject:\n  - $common\n  - team_data\nadd_parent: parent_key\n</code></pre> <pre><code>common:\n  content:\n    common_var: common_test\nteam_data:\n  content:\n    var: team1\n</code></pre> <p>The result:</p> <pre><code>prent_key:\n    content:\n        common_var: common_test\n        var: team1\n</code></pre>"},{"location":"build_strategies/reference/#for_each","title":"for_each","text":"<p><code>for_each</code> loops are used to build new objects based on data read from variables.</p>"},{"location":"build_strategies/reference/#standard-for_each-loop","title":"Standard for_each loop:","text":"<p>By default this loops adds the key it iterates over to the main result. </p> <pre><code>directory_data:\n  team1:\n    data:\n      path: team1\n      organization: organization1\n  team2:\n    data:\n      path: team2\n      organization: organization2\n</code></pre> <pre><code>for_each:\n  iterator: $directory_data\n  alias: directory_iterator\n  actions:\n    - inject:\n          - $each_value.data\n</code></pre> <p>The result <pre><code>team1: # &lt;- this key was added automatically by the loop \n  path: team1\n  organization: organization1\nteam2: # &lt;- this key was added automatically by the loop \n  path: team2\n  organization: organization2\n</code></pre></p> <p><code>iterator</code> - an object the loops iterates over</p> <p><code>alias</code> - it provides a name for the loop, the alias can be used to access the loop's data from an inner for loop. Without aliases it would not be possible to access data in the loop above the immediate parent as the immediate parent is accessed with <code>$each_key</code> and <code>$each_value</code>. An alias is accessed by using $ in front of alias name, and each_key and each_value are available by appending to the alias name with # in between. Examples are <code>$&lt;alias_name&gt;#each_key</code> and <code>$&lt;alias_name&gt;#each_value</code>.</p> <p><code>actions</code> - a list of actions that will be applied within the loops. Actions: <code>inject</code>, <code>add_parent</code>, <code>for_each</code></p> <p><code>$each_value</code> - an object in the current iteration. In the example above this is how <code>each_value</code> looks for the first iteration: <pre><code>    path: team1\n    organization: organization1\n</code></pre></p> <p><code>$each_key</code> - a string in the current iteration. In the example above the first iteration <code>each_key=path</code></p>"},{"location":"build_strategies/reference/#list-iterator-for_each-loop","title":"List iterator for_each loop:","text":"<p><code>list_iterator</code> loop iterates over string literals.</p> <pre><code>common_resources:\n  resources:\n    type_x:\n      common_resource_x_1:\n        type: resource\n      common_resource_x_2:\n        type: resource\n    type_y:\n      common_resource_y_1:\n        type: resource\n      common_resource_y_2:\n        type: resource\nteam_data:\n  resources:\n    type_x:\n        team_resource_x_1:\n          type: team_resource\n    type_y:\n        team_resource_y_1:\n          type: team_resource\n</code></pre> <pre><code>for_each:\n  list_iterator: [type_x, type_y]\n  alias: list_iterator\n  actions:\n    inject:\n      - $common.resources.$each_value\n      - team_data.resources.$each_value\n</code></pre> <p>The result:</p> <pre><code>common_resource_x_1:\n  type: resource\ncommon_resource_x_2:\n  type: resource\nteam_resource_x_1:\n  type: team_resource\ncommon_resource_y_1:\n  type: resource\ncommon_resource_y_2:\n  type: resource\nteam_resource_y_1:\n  type: team_resource\n</code></pre> <p>IMPORTANT: this type of for loop returns only <code>each_value</code></p>"},{"location":"build_strategies/reference/#variables","title":"Variables","text":""},{"location":"build_strategies/reference/#data","title":"data","text":"<p><code>data</code> loads data from the specified path. If the path is a directory, it loads all the files in that directory and stores them as one big object. Alternatively, an individual file can be specified as below.</p> <pre><code>variable_definitions:\n  common:\n    path: /common/ec2.yaml\n    type: data\n</code></pre>"},{"location":"build_strategies/reference/#data_with_key_from_path","title":"data_with_key_from_path","text":"<p><code>data_with_key_from_path</code> extends the data type functionality. The loaded data is organized based on a variable in curly braces. This data type is useful for for_each loops. </p> <pre><code>variable_definitions:\n    common:\n      path: /teams/{team}\n      type: data_with_key_from_path\n</code></pre> <p>Let's assume that we have the following paths: <pre><code>.\n\u251c\u2500\u2500 team1\n\u2502  \u251c\u2500\u2500 nested\n\u2502  \u2502  \u2514\u2500\u2500 second.yaml\n\u2502  \u2514\u2500\u2500 one.yaml\n\u2514\u2500\u2500 team2\n    \u251c\u2500\u2500 nested\n    \u2502  \u2514\u2500\u2500 second.yaml\n    \u2514\u2500\u2500 one.yaml\n</code></pre></p> <p>The loaded data for that example is:</p> <pre><code>team1:\n  &lt;merged_files_for_team1&gt;\nteam2:\n  &lt;merged_files_for_team2&gt;\n</code></pre>"},{"location":"build_strategies/reference/#data_with_key_from_object_field","title":"data_with_key_from_object_field","text":"<p><code>data_with_key_from_object_field</code> extends the base data type functionality. Apart from loading data it allows to manipulate the loaded object, like choosing only a part of the object and adding parents to it.</p> <pre><code>variable_definitions:\n    common:\n      path: /common/ec2.yaml\n      type: data_with_key_from_object_field\n      source_object_path: ec2\n      destination_object_path: my_resource\n</code></pre> <p>ec2.yaml <pre><code>ec2:\n  instance_type: t3.medium\n  owner: Mike\n</code></pre></p> <p>The loaded that would be:</p> <pre><code>my_resource:\n  instance_type: t3.medium\n  owner: Mike\n</code></pre>"},{"location":"build_strategies/reference/#where-next","title":"Where Next?","text":"<p>Learn all the CLI commands here.</p>"},{"location":"cli/","title":"ECS CLI Overview","text":"<p>The ECS CLI is used to interact with the ECS server. The CLI can only be used by authorized users. There are two user types, regular and admin.</p> <p>Actions CLI users can take are:</p> Action Admin Regular Create/ remove users X Grant access to areas of config hierarchy X Use build strategies X Edit build strategies (regular user needs --edit-strategies) X X Create / edit/ remove config at level of hierarchy they have been granted access to X X Consume pipeline config at level of hierarchy they have been granted access to X X Encrpyt secrets X X Decrpyt secrets (regular user needs --show-secrets) X X <p>When a config repo is empty, i.e, when initializing your ECS setup, the first user to interact with the CLI via <code>ecs init</code> automatically gets created as an admin user and that users access token is automatically stored in <code>~/.cto/ecs_settings.json</code>. </p> <p>Subsequent users need to provide a token for the user that has been created for them by an admin. Thr token is emitted on user creation.</p> <p>User config is saved in a file <code>~/.cto/ecs_settings.json</code> including the users server access token.</p>"},{"location":"cli/#cli-commands","title":"CLI Commands","text":"<p>A list of commands by function is provided in the following sections. </p>"},{"location":"cli/#admin-commands","title":"Admin Commands","text":"<p>User</p>"},{"location":"cli/#user-commands","title":"User Commands","text":"<p>Config Pull, Edit and Save</p> <p>Pipeline Config</p>"},{"location":"cli/admin-users/","title":"User Administration","text":"<p>All user admin functions are listed below for quick reference.</p>"},{"location":"cli/admin-users/#list-all-users","title":"List all users","text":"<p><code>cto ecs users list</code></p>"},{"location":"cli/admin-users/#user-creation","title":"User Creation","text":"<p>Users are stored in a secret file in repository <code>/_users.yaml</code>.  By default users don't have access to any config, they need authorizing with <code>ecs users auth</code> command, examples are provided here.</p> <p>When a new user is created, the CLI outputs a token that should be provided to the user along with their username. The user will be emailed to inform them their account has been created but we do not email their token. </p>"},{"location":"cli/admin-users/#create-a-basic-user","title":"Create a basic user","text":"<p><code>cto ecs users create --username &lt;username&gt; --given-name &lt;name&gt; --family-name &lt;name&gt; --email &lt;users email&gt;</code></p>"},{"location":"cli/admin-users/#create-an-admin-user","title":"Create an admin user","text":"<p><code>cto ecs users create --admin --username &lt;username&gt; --given-name &lt;name&gt; --family-name &lt;name&gt; --email &lt;users email&gt;</code></p>"},{"location":"cli/admin-users/#modify-an-admin-user-to-be-non-admin-user","title":"Modify an admin user to be non admin user","text":"<p><code>cto ecs users edit --no-admin --username &lt;username&gt;</code></p>"},{"location":"cli/admin-users/#create-a-basic-user-with-ability-to-read-secrets","title":"Create a basic user with ability to read secrets","text":"<p>This is typically needed only for a pipeline service account</p> <p><code>cto ecs users create --username &lt;username&gt; --given-name &lt;name&gt; --family-name &lt;name&gt; --email &lt;users email&gt; --read-secrets</code></p>"},{"location":"cli/admin-users/#remove-the-ability-to-read-secrets","title":"Remove the ability to read secrets","text":"<p><code>cto ecs users create --username &lt;username&gt; --no-read-secrets</code></p>"},{"location":"cli/admin-users/#create-a-basic-user-with-ability-to-edit-merge-strategies","title":"Create a basic user with ability to edit merge strategies","text":"<p><code>cto ecs users create --username &lt;username&gt; --given-name &lt;name&gt; --family-name &lt;name&gt; --email &lt;users email&gt; --edit-strategies</code></p>"},{"location":"cli/admin-users/#remove-ability-to-edit-merge-strategies","title":"Remove ability to edit merge strategies","text":"<p><code>cto ecs users edit --username &lt;username&gt; --no-edit-strategies</code></p>"},{"location":"cli/admin-users/#create-a-basic-user-with-ability-to-edit-webhooks","title":"Create a basic user with ability to edit webhooks","text":"<p><code>cto ecs users create --username &lt;username&gt; --given-name &lt;name&gt; --family-name &lt;name&gt; --email &lt;users email&gt; --edit-webhooks</code></p>"},{"location":"cli/admin-users/#remove-ability-to-edit-webhooks","title":"Remove ability to edit webhooks","text":"<p><code>cto ecs users edit --username &lt;username&gt; --no-edit-webhooks</code></p>"},{"location":"cli/admin-users/#user-authorization","title":"User Authorization","text":"<p>Users are authorized to access specific areas of config. If a user has access to <code>/teams/team-1</code> they will have access to all config underneath that directory. </p> <p>Admin users can access entire config, therefore admin access should be granted with caution.</p>"},{"location":"cli/admin-users/#list-paths-a-user-has-access-to","title":"List paths a user has access to","text":"<p><code>cto ecs users auth --action list --username &lt;username&gt;</code></p>"},{"location":"cli/admin-users/#authorize-user-to-specific-path","title":"Authorize user to specific path","text":"<p>To add a user to a path, navigate to the path. <code>cto ecs users auth add</code> commands are executed in the context of that path.</p> <p><code>cto ecs users auth --action add --username &lt;username&gt;</code></p>"},{"location":"cli/admin-users/#remove-authorization-for-a-specific-path","title":"Remove authorization for a specific path","text":"<p>To add a user to a path, navigate to the path. <code>cto ecs users auth delete</code> commands are executed in the context of that path.</p> <p><code>cto ecs users auth --action delete --username &lt;username&gt;</code></p>"},{"location":"cli/full-reference/","title":"CTO CLI","text":"<p>Usage:</p> <pre><code>$ version [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>-v, --version</code>: Print the version and exit</li> <li><code>--install-completion</code>: Install completion for the current shell.</li> <li><code>--show-completion</code>: Show completion for the current shell, to copy it or customize the installation.</li> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>ecs</code>: ECS CLI</li> </ul>"},{"location":"cli/full-reference/#version-ecs","title":"<code>version ecs</code>","text":"<p>ECS CLI</p> <p>Usage:</p> <pre><code>$ cto ecs [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>config</code></li> <li><code>init</code></li> <li><code>users</code></li> </ul>"},{"location":"cli/full-reference/#cto-ecs-config","title":"<code>cto ecs config</code>","text":"<p>Usage:</p> <pre><code>$ cto ecs config [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>build</code></li> <li><code>decrypt</code></li> <li><code>generate-schema</code></li> <li><code>pull</code></li> <li><code>push</code></li> <li><code>status</code></li> </ul>"},{"location":"cli/full-reference/#cto-ecs-config-build","title":"<code>cto ecs config build</code>","text":"<p>Usage:</p> <pre><code>$ cto ecs config build [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--path TEXT</code>: [required]</li> <li><code>--strategy-name TEXT</code></li> <li><code>--format TEXT</code></li> <li><code>--filter TEXT</code>: filter result using JMESPath</li> <li><code>--config-id TEXT</code></li> <li><code>--detect-drift / --no-detect-drift</code>: [default: no-detect-drift]</li> <li><code>--recursive / --no-recursive</code>: [default: no-recursive]</li> <li><code>--show-secrets / --no-show-secrets</code>: [default: no-show-secrets]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/full-reference/#cto-ecs-config-decrypt","title":"<code>cto ecs config decrypt</code>","text":"<p>Usage:</p> <pre><code>$ cto ecs config decrypt [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--path TEXT</code>: [required]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/full-reference/#cto-ecs-config-generate-schema","title":"<code>cto ecs config generate-schema</code>","text":"<p>Usage:</p> <pre><code>$ cto ecs config generate-schema [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--path TEXT</code>: [required]</li> <li><code>--strategy-name TEXT</code></li> <li><code>--write / --no-write</code>: [default: no-write]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/full-reference/#cto-ecs-config-pull","title":"<code>cto ecs config pull</code>","text":"<p>Usage:</p> <pre><code>$ cto ecs config pull [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/full-reference/#cto-ecs-config-push","title":"<code>cto ecs config push</code>","text":"<p>Usage:</p> <pre><code>$ cto ecs config push [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--tag TEXT</code></li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/full-reference/#cto-ecs-config-status","title":"<code>cto ecs config status</code>","text":"<p>Usage:</p> <pre><code>$ cto ecs config status [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/full-reference/#cto-ecs-init","title":"<code>cto ecs init</code>","text":"<p>Usage:</p> <pre><code>$ cto ecs init [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/full-reference/#cto-ecs-users","title":"<code>cto ecs users</code>","text":"<p>Usage:</p> <pre><code>$ cto ecs users [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>auth</code></li> <li><code>create</code></li> <li><code>delete</code></li> <li><code>edit</code></li> <li><code>list</code></li> <li><code>regenerate-token</code></li> </ul>"},{"location":"cli/full-reference/#cto-ecs-users-auth","title":"<code>cto ecs users auth</code>","text":"<p>Usage:</p> <pre><code>$ cto ecs users auth [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--username TEXT</code>: [required]</li> <li><code>--action [add|delete|list]</code>: [required]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/full-reference/#cto-ecs-users-create","title":"<code>cto ecs users create</code>","text":"<p>Usage:</p> <pre><code>$ cto ecs users create [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--username TEXT</code>: [required]</li> <li><code>--given-name TEXT</code>: [required]</li> <li><code>--family-name TEXT</code>: [required]</li> <li><code>--email TEXT</code>: [required]</li> <li><code>--admin / --no-admin</code>: [default: no-admin]</li> <li><code>--read-secrets / --no-read-secrets</code>: [default: no-read-secrets]</li> <li><code>--edit-strategies / --no-edit-strategies</code>: [default: no-edit-strategies]</li> <li><code>--edit-webhooks / --no-edit-webhooks</code>: [default: no-edit-webhooks]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/full-reference/#cto-ecs-users-delete","title":"<code>cto ecs users delete</code>","text":"<p>Usage:</p> <pre><code>$ cto ecs users delete [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--username TEXT</code>: [required]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/full-reference/#cto-ecs-users-edit","title":"<code>cto ecs users edit</code>","text":"<p>Usage:</p> <pre><code>$ cto ecs users edit [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--username TEXT</code>: [required]</li> <li><code>--given-name TEXT</code></li> <li><code>--family-name TEXT</code></li> <li><code>--email TEXT</code></li> <li><code>--admin / --no-admin</code></li> <li><code>--read-secrets / --no-read-secrets</code></li> <li><code>--edit-strategies / --no-edit-strategies</code></li> <li><code>--edit-webhooks / --no-edit-webhooks</code></li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/full-reference/#cto-ecs-users-list","title":"<code>cto ecs users list</code>","text":"<p>Usage:</p> <pre><code>$ cto ecs users list [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/full-reference/#cto-ecs-users-regenerate-token","title":"<code>cto ecs users regenerate-token</code>","text":"<p>Usage:</p> <pre><code>$ cto ecs users regenerate-token [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--username TEXT</code>: [required]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/user-config-manage/","title":"ECS CLI","text":"<p>The CLI is used to interact with the ECS server. A list of tasks and sample commands for each is listed below:</p>"},{"location":"cli/user-config-manage/#config-management-all-users","title":"Config Management (all users)","text":"<p>Config is stored in the Git repository with which the server is configured. Users work with either the whole or a subset of config. When a user pulls config, they will receive the latest version of any config that they are authorized to access. </p> <p>Commands to work with config are as follows:</p>"},{"location":"cli/user-config-manage/#retrieve-latest-config","title":"Retrieve latest config","text":"<p><code>cto ecs config pull</code></p> <p>This will output the config ID (commit hash) giving you a fixed version you can use in builds</p>"},{"location":"cli/user-config-manage/#save-config","title":"Save config","text":"<p><code>cto ecs config push</code></p> <p>If someone has edited any part of config you will not be able to push until you perform <code>cto ecs config pull</code> first. </p> <p>In the case where someone else has changed the same file as you, when you push you will be informed there is a merge conflict. Resolve this conflict as you would any Git merge conflict, examine the file(s) referenced, update to reflect correct changes and then do <code>git commit -am \"any message\"</code> and then <code>cto ecs config push</code> again. Note, the <code>git commit</code> is not ever sent to the server or the central repository, the merge resolution is handled in your local Git repo which is simply a repo with the config paths you are allowed to access.</p>"},{"location":"cli/user-config-manage/#show-status","title":"Show status","text":"<p><code>cto ecs config status</code></p> <p>This will tell you if you have made any changes that need to be pushed</p>"},{"location":"cli/user-config-manage/#save-config-and-tag","title":"Save config and tag","text":"<p><code>cto ecs config push --tag &lt;your tag&gt;</code></p>"},{"location":"cli/user-config-manage/#decrypt-secrets","title":"Decrypt secrets","text":"<p>Only works for users that have been created with the <code>--read-secrets</code> flag set</p> <p><code>cto ecs config decrypt --path &lt;path to file</code></p>"},{"location":"cli/user-config-manage/#use-ai-to-generate-a-schema","title":"Use AI to generate a schema","text":"<p><code>cto ecs config generate-schema --write --path config-examples/example-3 --strategy-name merge_common_ec2_to_teams_ec2</code></p> <p>The above command will create a schema file that will be used to validate the putput of the <code>cto ecs config build</code> command whenever the same path and strategy are built.</p>"},{"location":"cli/user-config-manage/#where-next","title":"Where Next?","text":"<p>Learn ECS CLI build commands for pipelines here</p>"},{"location":"cli/user-config-pipelines/","title":"ECS CLI","text":""},{"location":"cli/user-config-pipelines/#output-config-in-pipelines","title":"Output Config in Pipelines","text":"<p>Config for a specific path is compiled on the server according to a specified merge stratagy and returned in a suitable format with filtering applied. Some key things to remember:</p> <ul> <li> <p>Pipelines config is typically best authorized with a service user</p> </li> <li> <p>Grant the user access to the paths for which it will need access</p> </li> <li> <p>Decide if the pipeline user needs access to decrpyt secrets in the paths it has access to and configure it appropriately</p> </li> </ul>"},{"location":"cli/user-config-pipelines/#output-specific-path-only","title":"Output specific path only","text":"<p><code>cto ecs config build --path &lt;path&gt;</code></p>"},{"location":"cli/user-config-pipelines/#output-specific-path-only-with-a-specific-config-id","title":"Output specific path only with a specific config ID","text":"<p>Config IDs are versions of config, either tags that are added via the CLI or commit hashes that are output on each build. </p> <p><code>cto ecs config build --path &lt;path&gt; --config_id 1.0.1</code></p>"},{"location":"cli/user-config-pipelines/#output-specific-path-only-with-a-specific-config-id-and-check-if-config-has-changed","title":"Output specific path only with a specific config ID and check if config has changed","text":"<p>If someone has edited common config, or some other config that is being used by your build strategy, <code>--drift-detect</code> will build both configs and if they are different, it will fail your pipeline so you can either run it with upgraded the config after you have tested the new version.</p> <p><code>cto ecs config build --path &lt;path&gt; --config_id 1.0.1 --detect-drift</code></p>"},{"location":"cli/user-config-pipelines/#output-specific-path-only-with-yaml-output-instead-of-json","title":"Output specific path only with YAML output instead of JSON","text":"<p><code>cto ecs config build --path &lt;path&gt; --format yaml</code></p>"},{"location":"cli/user-config-pipelines/#output-specific-path-with-secret-decryption","title":"Output specific path with secret decryption","text":"<p><code>cto ecs config build --path &lt;path&gt; --show-secrets</code></p>"},{"location":"cli/user-config-pipelines/#output-specific-path-and-all-config-underneith","title":"Output specific path and all config underneith","text":"<p><code>cto ecs config build --path &lt;path&gt; --recursive</code></p>"},{"location":"cli/user-config-pipelines/#output-specific-path-with-a-specific-strategy","title":"Output specific path with a specific strategy","text":"<p><code>cto ecs config build --path &lt;path&gt; --strategy-name &lt;strategy name&gt; --show-secrets</code></p>"},{"location":"cli/user-config-pipelines/#output-specific-path-with-a-specific-strategy-and-filtering","title":"Output specific path with a specific strategy and filtering","text":"<p><code>cto ecs config build --path &lt;path&gt; --strategy-name &lt;strategy name&gt; --filter '\"some-field\".\"some-other-deeper-nested-field\"'</code></p> <p>Note, filters follow JMSPath syntax. Read about JMSPath and try out filtering in the playground here.</p>"},{"location":"cli/user-config-pipelines/#where-next","title":"Where Next?","text":"<p>Learn all ECS CLI commands here</p>"},{"location":"config/","title":"Your First Config","text":"<p>If you followed the Getting Started steps, you now have ECS On-Premise server installed or have an ECS Cloud account, and have installed and initialized the CLI. Now it's time to create a config.</p> <p>You can either read the config explanations below copying and pasting in examples, or you can skip ahead and build a config from scratch.</p>"},{"location":"config/#use-provided-examples","title":"Use Provided Examples","text":"<p>1) Change into the config repository directory you setup when you installed and initialised the CLI. Make sure you are in the <code>repo</code> subdirectory</p> <p>2) If you installed ECS On-Premise server you've probably cloned the Getting Started Repo to get this far. If this is the case you can copy the /config-examples directory from the Getting Started Repo to your config repository <code>repo</code> directory.</p> <p>If you have an ECS Cloud account and therefore didn't need to clone the repo, you can change to the <code>repo</code> directory in your config repository and download all the examples by using the command below:</p> <p><code>wget -O - https://github.com/Cloud-Technology-Office/ecs-getting-started/archive/main.zip | tar xz --strip=2 \"ecs-getting-started-main/config-examples\"</code></p>"},{"location":"config/#yaml-json-based-examples","title":"YAML/ JSON Based Examples","text":"<p>Let's build the config in the examples, just as you would in your pipelines:</p>"},{"location":"config/#example-1-most-basic-of-configs-with-no-merging","title":"Example 1 (most basic of configs with no merging)","text":"<p>We call this legacy, it's probably how most of you are doing config today, one config per pipeline or per instantiation of the pipeline. </p> <p>Jenkins or some other pipeline tool might be passing in a team name, region, environment or accopunt ID in order for a script to  choose the right variables file. This is a very typical approach to sourcing variables.</p> <p>In this example we use pipeline 1 and pipeline 2 to represent different ways you might call your pipeline but with different variables, such as multiple tfvars files. Imagine pipeline 1 might be 1 environment tfvars and pipeline 2 is another one. </p> <p>If you are using this approach, ECS will almost certainly be a drop in replacement for variables files used in your pipelines today, all you would need to do is let ECS generate the variables file from centralized config prior to pipeline run using the commands used in this example. </p> <p>Using ECS Cloud it is likely you could go from legacy config to signup and go live with this approach inside 30 minutes. After you have got to that stage, then you can strealine your config from there as the rest of the examples will teach you. </p> <p>Repo Example 1</p> <p> Commands used:  </p> <ul> <li><code>cto ecs config build --path config-examples/example-1/user-1 --recursive</code> </li> </ul> <p> Command used:  </p> <ul> <li> <p><code>cto ecs config build --path config-examples/example-1/user-2 --recursive --filter ec2</code> </p> </li> <li> <p><code>cto ecs config build --path config-examples/example-1/user-2 --recursive --filter 'ec2.\"user-2-instance-a\"'</code> </p> </li> </ul> <p>You can see user-2 had a slightly different config, and then we filtered it to retrieve just a single instance.</p> <p>But isn't the goal of ECS is to move beyond this legacy approach and become more DRY.  Imagine when used at scale, if you need to change the AMI for all pipelines.</p> <p>Let's move to a more DRY world.</p>"},{"location":"config/#example-2-get-more-dry-and-do-a-basic-merge","title":"Example 2 (Get more DRY and do a basic merge)","text":"<p>Repo Example 2</p> <p></p> <p>Command used:  </p> <ul> <li><code>cto ecs config build --path config-examples/example-2 --recursive</code></li> </ul> <p>Here, the content has been recursively merged from top to bottom. This only works for hierarchies that only have 1 path. For more than 1 team, you need to use strategies to tell the merger what to do. </p>"},{"location":"config/#example-3-use-a-basic-strategy","title":"Example 3 (Use a basic strategy)","text":"<p>In this example we have a merge strategy defined that will load a common directory and build config for each team by merging their overrides over the top of common.</p> <p>Repo Example 3</p> <p></p> <p>Command used:  </p> <ul> <li><code>cto ecs config build --path config-examples/example-3 --strategy-name merge_common_ec2_to_teams_ec2</code></li> </ul>"},{"location":"config/#example-4-use-a-multi-object-strategy","title":"Example 4 (Use a multi object strategy)","text":"<p>In this example we will emit config for moore objects, not just the EC2 object.</p> <p>Repo Example 4</p> <p></p> <p>Command used:  </p> <ul> <li><code>cto ecs config build --path config-examples/example-4 --strategy-name merge_common_objects_to_teams_objects</code></li> </ul> <p>If you wanted to emit more objects, just edit the list_iterator to add more.</p>"},{"location":"config/#example-5-use-a-config-generation-strategy-to-generate-ec2s","title":"Example 5 (Use a config generation strategy to generate EC2s)","text":"<p>In this example we're going to generate config based on a list of configurations we would like. We will base it on common and expand it into multiple instances of the same config with named identifiers and with instance level override. </p> <p>Note in the output, how disk_size has been overriden for each team and instance. This is so useful if you want to have a pipeline manage a set of resources, such as Terraform doing a <code>for_each</code> over each instance. </p> <p>Repo Example 5</p> <p></p> <p>Command used:  </p> <ul> <li><code>cto ecs config build --path config-examples/example-5 --strategy-name generate_ec2s</code></li> </ul> <p>Let's assume the pipeline runs per team instead of all teams, to emit the config for team 1 only, and only for the <code>ec2</code> object, just add <code>--filter '\"team-1\".ec2'</code> on the end of the command.</p> <p></p> <p>Command used:  </p> <ul> <li><code>cto ecs config build --path config-examples/example-5 --strategy-name generate_ec2s --filter '\"team-1\".ec2'</code></li> </ul>"},{"location":"config/#example-6-use-a-config-generation-strategy-to-generate-more-objects","title":"Example 6 (Use a config generation strategy to generate more objects)","text":"<p>Example 5 was only looking at <code>ec2</code> objects, let's extend that to cater for more object types.</p> <p>Repo Example 6</p> <p></p> <p>Command used:  </p> <ul> <li><code>cto ecs config build --path config-examples/example-6 --strategy-name generate_listed_objects</code></li> </ul> <p>You will see that we removed the hard coded <code>ec2</code> reference and instead iterate over a list of object types. </p>"},{"location":"config/#pkl-examples","title":"Pkl Examples","text":"<p>Using Pkl in ECS is really as simple as putting your Pkl files into a path in your config and using the following command to compile it:</p> <p><code>cto ecs config build --path &lt;path to root Pkl file&gt;</code></p> <p>When passing the <code>--format</code> option to the CLI, ECS will pass this to the Pkl binary and will return the requested format if the particular Pkl config supports that format. Where outout from Pkl comnfig is multi file YAML, the <code>--format</code> option is ignored.</p>"},{"location":"config/#example-7-a-simple-pkl-example","title":"Example 7 (A simple Pkl example)","text":"<p>Commands used:</p> <p><code>cto ecs config build --path config-examples/example-7/birds.pkl</code> </p> <p><code>cto ecs config build --path config-examples/example-7/birds.pkl --format yaml</code></p> <p><code>cto ecs config build --path config-examples/example-7/birds.pkl --format xml</code></p> <p><code>cto ecs config build --path config-examples/example-7/birds.pkl --format properties</code></p> <p><code>cto ecs config build --path config-examples/example-7/birds.pkl --format plist</code></p>"},{"location":"config/#example-8-a-complex-pkl-example","title":"Example 8 (A complex Pkl example)","text":"<p>Pkl isn't always one file or even just local imports in a multi file config. This example pulls in external dependencies and outputs multi file YAML output. In the case where Pkl emits multi file YAML, the <code>--format</code> option is ignored.</p> <p></p> <p>Command used:</p> <p><code>cto ecs config build --path config-examples/example-8/k8s-frontend.pkl</code></p>"},{"location":"config/#example-9-a-multi-pkl-file-glob-build","title":"Example 9 (A multi Pkl file glob build)","text":"<p>This example uses a glob pattern to match multiple files. </p> <p></p> <p>Command used:</p> <p><code>cto ecs config build --path /\"config-examples/example-9/*/staging/us-west/*.pkl\"</code></p> <p>And because this is an entire app manifest in multi file YAML format, it can be directly applied to your K8s cluster as follows:</p> <p><code>cto ecs config build --path /\"config-examples/example-9/*/staging/us-west/*.pkl\" | kubectl apply -f -</code></p>"},{"location":"config/#example-10-a-complete-reference-config","title":"Example 10 (A complete reference config)","text":"<p>Example 10 demonstrates how a configuration can be build to serve multiple teams needs. Is has config for core infrastructure, and also config specific to individual teams. It is a comprehensive example that is well documented in the getting started repo. See example 10.</p>"},{"location":"config/#learn-and-build-from-scratch","title":"Learn and Build from Scratch","text":"<p>Alternatively you can follow along below and create your own config from scratch and adapt the content and commands to suit.</p> <p>1) Let's create a very basic config:, we'll create a team based config, each team will have their own settings for an EC2. Note, <code>team 2</code> has a different VPC name than <code>team-1</code>.</p> <p>Important: Your config directory has been initialized as a local Git repo, it lives in a subdirectory <code>repo</code>. Your config needs to live in the <code>repo</code> directory, and all ECS commands take place in that directory.</p> <p></p> <p>Gif Content: (1)</p> <ol> <li> <p><code>teams/team-1/ec2.yaml</code> (1)</p> <ol> <li><pre><code>ec2:\n  instance_type    : t2.medium\n  user_data        : null\n  ami              : ami-123456789\n  instance_profile : instance-profile-1\n  disk_size        : 200\n  vpc_name         : team-1-vpc\n  tags:\n    terraform : true\n</code></pre></li> </ol> <p><code>teams/team-2/ec2.yaml</code> (1)</p> <ol> <li><pre><code>ec2:\n  instance_type    : t2.medium\n  user_data        : null\n  ami              : ami-123456789\n  instance_profile : instance-profile-1\n  disk_size        : 200\n  vpc_name         : team-2-vpc\n  tags:\n    terraform : true\n</code></pre></li> </ol> <p><code>cto ecs config push</code></p> </li> </ol> <p>We've now created config for 2 teams and pushed it to ECS. You could take a look at your repository now and you will see what ECS is storing there. Note, _users.yaml file has your initial admin user with encrypted token stored. </p> <p>2) Now let's see how we can consume that in a pipeline.</p> <p>The <code>cto ecs config build</code> command is what you use in your pipelines to generate consumable config. It has a <code>--path</code> parameter that allows config to be be extracted from anywhere in the path. If we specified <code>cto ecs config build --path /teams/team-2</code> we will get the following returned:</p> <pre><code>{\n  \"ec2\": {\n    \"instance_type\": \"t2.medium\",\n    \"user_data\": null,\n    \"ami\": \"ami-123456789\",\n    \"instance_profile\": \"instance-profile-1\",\n    \"disk_size\": 200,\n    \"vpc_name\": \"team-2-vpc\",\n    \"tags\": {\n      \"terraform\": true\n    }\n  }\n}\n</code></pre> <p>If we only want the content under the <code>ec2</code> object, which is likely for your pipeline code, use <code>--filter</code> parameter to filter content out of the returned config. Let's see it in action:</p> <p> Gif Content: (1)</p> <ol> <li><code>cto ecs config build --path /teams/team-2</code></li> </ol> <p>But how is that DRY I hear you say. Well, it's not, but it probably looks like many of your existing pipeline configurations. Now let's put the ECS touch on it and make it DRY!</p> <p>First let's restructure the configuration a to give it a section for common config, then we'll override just the parameters that are different. In our example above, <code>team-2</code> had a specific VPC <code>team-2-vpc</code> whereas <code>team-1</code> had <code>default</code>. If the majority of teams had a VPC called <code>default</code> that should be the setting in common. Let's also override the default <code>disk_size</code> for <code>team-1</code>.</p> <p> Gif Content: (1)</p> <ol> <li> <p><code>teams/common/ec2.yaml</code> (1)</p> <ol> <li><pre><code>ec2:\n  instance_type    : t2.medium\n  user_data        : null\n  ami              : ami-123456789\n  instance_profile : instance-profile-1\n  disk_size        : 200\n  vpc_name         : default\n  tags:\n    terraform : true\n</code></pre></li> </ol> <p><code>teams/teams/team-1/ec2.yaml</code> (1)</p> <ol> <li><pre><code>ec2:\n  disk_size        : 300\n</code></pre></li> </ol> <p><code>teams/teams/team-2/ec2.yaml</code> (1)</p> <ol> <li><pre><code>ec2:\n  vpc_name        : team-2-vpc\n</code></pre></li> </ol> </li> </ol> <p>Now let's add a strategy. </p> <p>In the teams directory, create <code>__strategies.yaml</code></p> <p>The contents is as follows:</p> <p><code>/teams/__strategies.yaml</code> - Note, this is in top level teams directory. <pre><code>strategies:\n  teams_merge_common:\n    operations:\n      - for_each:\n          iterator: $directory_data\n          actions:\n            - inject:\n              - $common\n              - $each_value.ec2\n            - add_parent: ec2\n    variable_definitions:\n      common:\n        path: ./common/\n        type: data_with_key_from_object_field\n        source_object_path: ec2\n        destination_object_path: ''\n      directory_data:\n        path: ./teams/{team}/\n        type: data_with_key_from_path\n</code></pre></p> <p>Next you need to push the config with <code>cto ecs config push</code>.</p> <p>Now let's see how to consume DRY config in your pipeline. To do this we'll use the follow command:</p> <p><code>cto ecs config build --path teams --strategy-name teams_merge_common</code></p> <p>And we'll filter the output to get just <code>team-1</code></p> <p><code>cto ecs config build --path teams --strategy-name teams_merge_common --filter '\"team-1\"'</code></p> <p>And we'll filter the output to get just <code>team-1</code> <code>ec2</code> object.</p> <p><code>cto ecs config build --path teams --strategy-name teams_merge_common --filter '\"team-1\".ec2'</code></p> <p>Note, filters follow JMSPath syntax. Read about JMSPath and try out filtering in the playground here.</p> <p></p>"},{"location":"config/#where-next","title":"Where Next?","text":"<p>Learn ECS strategies here</p>"},{"location":"config/architecture/","title":"Architecture","text":""},{"location":"config/architecture/#is-you-are-using-apple-silicone","title":"Is you are using Apple Silicone","text":"<p>COMPOSE_DOCKER_CLI_BUILD=1 \\ DOCKER_BUILDKIT=1 \\ DOCKER_DEFAULT_PLATFORM=linux/amd64 \\ docker-compose build</p>"},{"location":"config/pkl/","title":"Overview of ECS Pkl Support","text":"<p>As a configuration platform, we decided to build in Pkl support so that users have an alternative to our YAML strategies language for building DRY configurations. Pkl also provides this functionality, and is a valid choice for a user of ECS that is already using Pkl for their configurations. </p> <p>It is perfectly OK to mix Pkl and YAML and JSON in the same ECS repository, even in the same path, but typically, a Pkl configuration would be stored in its own config path.</p> <p>The great thing about using Pkl with the ECS platform is that no matter what config language you want to use for a particular project, you always use the same build commands. No need to install Pkl anywhere, the ECS server handles all the compilation and the CLI returns results to std out or file if using the <code>--out</code> option. </p> <p>Pkl output format options are controlled via the <code>--format</code> command line flag. All options Pkl supports are supported through the ECS CLI. Note, only JSON and YAML output formats work with ECS schema validation. </p> <p>At the time of writing the current Pkl binary version is <code>0.25.3</code>.</p>"},{"location":"config/pkl/#pkl-vs-yaml-json-feature-comparisons","title":"Pkl vs YAML/ JSON Feature Comparisons","text":"<p>There are a few differences in capabilities and techniques to use when using the 2 language options. Those are explored below.</p>"},{"location":"config/pkl/#ecs-build-file-paths","title":"ECS Build File Paths","text":"<p>When using Pkl, on the <code>cto config build --path</code> command you always specify the path to target one or more .pkl files. The most basic example is a single file but ECS also supports passing Pkl glob patterns just as you would if you were calling the Pkl binary directly. Examples are provided below:</p>"},{"location":"config/pkl/#single-file","title":"Single file:","text":"<p><code>cto config build --path \"species/birds.pkl\"</code></p>"},{"location":"config/pkl/#multiple-files-in-one-directory","title":"Multiple files in one directory","text":"<p>The following command would produce a multi file YAML output that is piped directly into kubectl.</p> <p><code>cto config build --path \"/team-1/guestbook/production/us-west/*.pkl\" | kubectl apply -f -</code></p>"},{"location":"config/pkl/#all-pkl-files-in-path","title":"All Pkl files in path","text":"<p><code>cto config build --path \"/team-1/**/*.pkl\"</code></p> <p>By contrast, using ECS own YAML/ JSON merge strategies, it is possible to build a single file or an entire directory structure with no specification of a file or glob by virtue of the ECS strategy language. An example follows:</p> <p><code>cto ecs config build --path /config-examples/example-4 --strategy-name generate_ec2s</code></p> <p>This command has only specified the directory name and all the compilation logic to merge config from multiple directories and files is stored in <code>__strategies.yaml</code> strategy <code>generate_ec2s</code>. See build strategies for more information.</p> <p>In summary, in Pkl the compilation logic is embedded in the config, with ECS processing YAML / JSON, it is external to the config and is stored in strategies files. </p>"},{"location":"config/pkl/#ecs-feature-comparison-table","title":"ECS Feature Comparison Table","text":"<p>A comparison of ECS feature support as of today is provided below. Our roadmap is moving towards feature parity for both config languages:</p> Feature YAML/ JSON Pkl Webhooks (trigger pipelines on changes) X X AI Based Schema Generation/ Validation X X Config Versioning (allows pipeline pinning and rollback) X X Config Drift Detection X Secret Management (store encrypted secrets in config) X"},{"location":"config/pkl/#where-next","title":"Where Next","text":"<p>See Pkl in action in ECS here.</p>"},{"location":"drift_detection/","title":"Configuration Drift Detection","text":""},{"location":"drift_detection/#overview","title":"Overview","text":"<p>As ECS uses common areas of config to facilitate DRY, another user may have upgraded something in the config that would affect a production pipeline. For this reason, in the case of production pipelines, it is typical to fix the version of config that is being used. </p> <p>This is where Drift Detection comes in. </p>"},{"location":"drift_detection/#fixing-config-version","title":"Fixing Config Version","text":"<p>When a configuration is pushed, it returns a build ID. The build ID is the commit hash. This can be used to emit a specific version of config to a pipeline as follows:</p> <p><code>cto ecs config push</code></p> <p>This returns build ID that is then used in config build as follows:</p> <p><code>cto ecs config build --path &lt;path&gt; --config-id &lt;build ID&gt;</code></p> <p>Every time the config is built, it will be the same regardless of anyone elses changes. </p> <p>Let's say you don't know the build ID as you have not pushed any new config, but you want to fix the version. This is where tagging comes in. </p>"},{"location":"drift_detection/#config-version-tagging","title":"Config Version Tagging","text":"<p>Tag the config at a particular point using thw following command:</p> <p><code>cto ecs config push --tag &lt;tag&gt;</code></p> <p>Run your pipeline and if it is successful, use that tag for future builds. If it fails and you need to adjust config, either use the emitted build ID from your config push or re-tag and use the tag.</p>"},{"location":"drift_detection/#how-does-drift-detection-work","title":"How Does Drift Detection Work?","text":"<p>Now you have your pipeline running on a fixed version of config, what if someone makes a change that should affect your pipeline, such as updating an AMI ID, changing a cost center tag, adding new region support, the list goes on. You may not be aware this change has been made but it should be deployed using your pipeline. </p> <p>Using the <code>--detect-drift</code> flag in conjunction with <code>--config-id</code> flags will cause a pipeline to fail if there is a new version of config available. This gives you a chance to observe the changes in the build output and re-tag and update your config build ID.</p> <p>An example output where someone changed the common value for default instance size is as follows:</p> <p></p> <p>We are also working on a feature that will automatically notify you via email when a new version of config is available for your pipeline. </p>"},{"location":"drift_detection/#where-next","title":"Where Next?","text":"<p>Check out the CLI reference here</p>"},{"location":"installation/cli/","title":"Install and Setup CTO CLI","text":"<p>The ECS server should now be setup, if not, follow instructions here.</p> <p>1) Ensure you have Python 3.8 or newer and install the CTO CLI with <code>pip install cto-cli</code></p> <p>2) Create an empty directory in which you will create your first configuration. This configuration will be pushed to the server/ centralized repo and will then be available to other ECS users and of course, your pipelines.</p> <p>3) Change to your config directory</p> <p>4) Initialize the ECS CLI:</p>"},{"location":"installation/cli/#ecs-cloud","title":"ECS Cloud","text":"<p>If you are setting up ECS Cloud initialize as below:</p> <p></p> <p>Note, the ECS Token comes from https://account.cloudtechnologyoffice.com portal, just click no product ECS, then Cloud details. </p>"},{"location":"installation/cli/#ecs-on-premise","title":"ECS On-Premise","text":"<p>If you are setting up ECS On-Premise initialize as below:</p> <p></p> <p>Command used: <code>cto ecs init</code></p> <p>5) You are now logged on as an administrator, your user got automatically created, your user token was automatically encrypted in the __users.yaml file in the root of your repo, and your user token was returned by the CLI and stored in <code>/.cto/ecs_settings.json</code>. </p> <p>6) A subdirectory of your created empty directory has been created, it is called <code>repo</code>, change to this directory. </p> <p>7) Let's get the config from the server, this will initialize your local config store with any config the user is authorized to work with, in your case, you are admin so you can see the entire config.</p>"},{"location":"installation/cli/#where-next","title":"Where Next?","text":"<p>Learn about configuration here</p>"},{"location":"installation/cloud/","title":"ECS Cloud","text":"<p>You have a choice of using ECS Cloud or ECS On-Premise. If you choose to use ECS Cloud you're in the right place. Follow the steps below to get started. If you want to try ECS On-Premise, click here.</p> <p>ECS Cloud gives you total control over your configuration. Whilst we are hosting the ECS server, you still use your own private repository to store the configuration. In addition, we encrypt secrets using either a key that we create especially for your ECS Organization, or you can choose to use your own encryption key hosted on any of AWS, Azure or GCP. </p> <p>Using your own encryption key is the best option for anything other than giving ECS a try as it will enable you to transition to ECS On-Premise very easily if you need to. You can start your ECS journey in the cloud and then simply install ECS server on-premise, use the same repository and encryption key and the transition is complete. This is possible since you supply the configuration repository. </p>"},{"location":"installation/cloud/#lets-get-started","title":"Let's get started!","text":"<p>1) Create a private repository in your Git server of choice, leave it empty</p> <p>2) Create a token that has write access to the repository</p> <p>3) Signup for ECS Cloud Free Trial or paid plan here</p> <p></p> <p>In this example I will choose the Free Trial. If you choose a paid option, you will be asked for payment information in order to enable your plan. </p> <p>When you signup you will have an option to configure your ECS Cloud Organization. </p> <p></p> <p>Your username and password that you need to sign in to your CTO account will be emailed to you. Sign in and you will see the following:</p> <p></p> <p>Click on Enterprise Self Service and you will see your ECS plan details:</p> <p></p> <p>Click on CREATE ECS CLOUD Organization and then fill in your Git and encrpyption key details (see Encryption Key Options).</p> <p>If you haven't created an empty repository for your confiiguration, now is the time to do it. Make sure you create an access token that has read/ write privileges to the repo. Fill in repo and access token details, select encryption option and click SAVE. </p> <p></p> <p>4) Install the ECS CLI by installing Python 3.8 or above and then install with <code>pip install cto-cli</code>.</p> <p>5) Copy your ECS API Token from your ECS Organization Settings page as below:</p> <p></p> <p>Now you have the API token, configure the CLI here.</p>"},{"location":"installation/cloud/#multiple-configuration-repository-support","title":"Multiple Configuration Repository Support","text":"<p>ECS supports an unlimited number of indpendent configuration repositories. Even large organizations can organize the stucture of a single repository to fulfull the entire organizations needs, but where there is a need for greater segregation between org units or teams, ECS fully supports this.</p> <p>An end user uses the ECS CLI to interact with a single repository. The repository name is configured when the CLI is configured.</p> <p>To add multiple repositories, simply click ADD REPO as per screenshot below:</p> <p></p>"},{"location":"installation/cloud/#encryption-key-options","title":"Encryption Key Options","text":"<p>Create a key for SOPS to use for secret encryption:</p> <ul> <li> <p>AWS</p> <ul> <li>Either use a KMS encryption key that we create specifically for your ECS Organization or create your own</li> <li>If you create your own KMS key, ECS Cloud can access it via:<ul> <li>A role that you provide (recommended). Note. We create a role in ECS Cloud specifically for your ECS Organization. You will configure your role to trust only your ECS Cloud role so rest assured no other ECS Cloud user can access your key</li> <li>Provide user credentials in the form on AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY</li> </ul> </li> </ul> </li> <li> <p>Azure</p> <ul> <li>Create an Microsoft Vault key</li> <li>Create a Service Principle that has role \"Key Vault Crypto User\" granted for the key</li> <li>Note the following Service Principle variables<ul> <li>appId (ECS CLient ID)</li> <li>password (ECS Client Secret)</li> <li>tenant (ECS Tenant ID)</li> </ul> </li> <li> <p>GCP</p> </li> <li> <p>Create a GCP Vault and key or add a key to an existing vault</p> </li> <li>Create a service account for ECS that has decrypt access to the key</li> <li>Copy the service account credentials file and paste it in to your ECS Organization Settings page in the appropriate field</li> </ul> </li> </ul>"},{"location":"installation/cloud/#where-next","title":"Where Next?","text":"<p>Install and setup the CTO CLI to interact with the ECS Cloud by following instructions here.</p>"},{"location":"installation/coming_soon/","title":"ECS Getting Started Repository","text":"<p>The target release date for ECS is end March 2024. The getting started repository will be available from ECS release date. </p>"},{"location":"installation/server/","title":"ECS On-Premise","text":"<p>You have a choice of using ECS Cloud or ECS on-premise. If you choose to run ECS on-premise you're in the right place. Follow the steps below to get started. If you want to try ECS Cloud, click here</p> <p>By running ECS on your personal machine it is possible to get up to speed on how it works and to start small by creating configuration for a new pipeline you are creating, retrofit into an existing pipeline or you can build the beginnings of your enterprise configuration.</p> <p>When you're ready to go into production, it's easy to deploy to Kubernates, AWS Fargate etc. Just follow the docker-compose settings.</p>"},{"location":"installation/server/#lets-get-started","title":"Let's get started!","text":"<p>1) Clone the  getting started repo</p> <p>2) Create a repository in your Git server of choice, leave it empty</p> <p>3) Create a Git token that has write access to the repository</p> <p>4) Install the ECS CLI by doing <code>pip install cto-cli</code></p> <p>5) Create a key for SOPS to use for secret encryption:</p> <ul> <li> <p>AWS</p> <ul> <li>Create an AWS KMS key and note it's ARN.</li> <li>Get AWS CLI creds that have access to the key typically via an AWS profile or via SSO CLI credentials. </li> </ul> </li> <li> <p>Azure</p> <ul> <li>Create an Microsoft Vault key</li> <li>Create a Service Principle that has role \"Key Vault Crypto User\" granted for the key</li> <li>Take a note of the following Service Principle variables<ul> <li>appId</li> <li>password</li> <li>tenant</li> </ul> </li> </ul> </li> <li> <p>GCP</p> <ul> <li>Create a GCP Vault and key or add a key to an existing vault</li> <li>Create a service account for ECS that has decrypt access to the key</li> <li>Note the service account credentials file location for your environment variables as below</li> </ul> </li> </ul> <p>6) Obtain an ECS API key, here. Note, only paid plans support on-premise. If you are unable to trial using ECS Cloud, contact us and we'll set you up a dedicated license.</p> <p>7) Edit docker-compose.yaml environment variable values as below:</p> <p>Note, ECS supports multiple configuration repositories. Each repository needs a name, and a user of that repository configures their CLI client to communicate with that repository. In the example below, the repository has been named REPO1, choose any name (upper case alphanumeric only).</p> <p>It is possible to have encryption keys in different clouds for each repository, or all repositories can use the same key.</p> <pre><code>version: '3.7'\n\nservices:\n  api:\n    image: cloudtechnologyoffice/ecs\n    ports:\n      - '8000:8000'\n    environment:\n      ACCEPT_EULA: Y\n\n      ECS_API_KEY: \"&lt;The API key you have been issued when you signed up for ECS&gt;\"\n\n      REPOSITORY_REPO1_URL: \"&lt;Empty configuration repository URL&gt;\"\n      REPOSITORY_REPO1_PROVIDER: \"&lt;github|bitbucket|gitlab|azure&gt;\"\n      REPOSITORY_REPO1_ACCESS_TOKEN: \"&lt;Token with read/write access an empty Git repo that will be used for config storage&gt;\"\n\n      # ENCRYPTION KEY SPECIFICATION AND CREDENTIALS\n\n      # If using AWS KMS, set the following variables\n\n      # REPOSITORY_REPO1_SOPS_KMS_ARN: \"&lt;AWS KMS key ARN&gt;\"\n\n      # AWS_ACCESS_KEY_ID: \"&lt;AWS_ACCESS_KEY_ID&gt;\"\n      # AWS_SECRET_ACCESS_KEY: \"&lt;AWS_SECRET_ACCESS_KEY&gt;\"\n      # AWS_SESSION_TOKEN: \"&lt;AWS_SESSION_TOKEN&gt;\"\n      # or \n      # if container running in AWS with role that can access KMS key, no vars required\n\n\n      # If using Azure Vault, set the follow variables\n\n      # REPOSITORY_REPO1_SOPS_AZURE_KV: &lt;Key URL. i.e. https://&lt;Vault name&gt;.vault.azure.net/keys/&lt;key name&gt;/&lt;string&gt;\n\n      # AZURE_TENANT_ID: &lt;tenant ID for the Service Principle&gt;\n      # AZURE_CLIENT_ID: &lt;appId for the Service Principle&gt;\n      # AZURE_CLIENT_SECRET: &lt;password for the Service Principle&gt;\n\n\n      # If you are using GCP Vault, set the following variable\n\n      # REPOSITORY_REPO1_SOPS_GCP_KMS: projects/&lt;project&gt;/locations/global/keyRings/&lt;keyring&gt;/cryptoKeys/&lt;key name&gt;\n\n      # GOOGLE_APPLICATION_CREDENTIALS: \"${VOLUME_MAPPED_DIR}/&lt;MyGoogleServiceAccountJsonFile.json&gt;\"\n      # or \n      # GOOGLE_CREDENTIALS: \"&lt;String encoded JSON Google credentials file\"\n</code></pre> <p>AWS Note: For local use with docker compose, if you have an AWS profile configured, you do not need to set the AWS_ values above in the compose file.</p> <p>Azure Note: For local use, if you are logged in via <code>az login</code>, you do not need to set the AZURE_ values above in compose file.</p> <p>GCP Note: For local use, if you are logged in via <code>gloud auth login</code>, you do not need to set the GOOGLE_ value above in compose file.</p> <p>8) Uncommment your cloud providers SOPS settings in <code>docker-compose.yaml</code>.</p> <p>9) Use <code>docker-compose up</code> to start ECS server.</p> <p>That's ECS setup and ready to use. It already supports secret encryption as you specified the KMS key to encrypt so any secrets you want to store, go right ahead. See Secret storage for more information on how to designate a key as a secret.</p>"},{"location":"installation/server/#multiple-configuration-repository-support","title":"Multiple Configuration Repository Support","text":"<p>ECS supports an unlimited number of indpendent configuration repositories. Due to ECS RBAC, even large organizations can organize the stucture of a single repository to fulfull the entire organizations needs, but where there is a need for greater segregation between org units or teams, ECS fully supports this.</p> <p>An end user uses the ECS CLI to interact with a single repository. The repository name is configured when the CLI is initialized.</p> <p>To configure ECS server with multiple repositories, multiple sets of environment variables are defined in docker compose environment section. In the example below, we have 3 repos, the first is called REPO1, second is REPO2 and third is REPO3. REPO1 uses an encrption key in AWS, REPO2 uses Azure and REPO3 uses GCP. </p> <p>Typically your repos would have meaningful names such as TEAM-DEVOPS or in the case of geographic separation, perhaps UK or USA.</p> <pre><code>REPOSITORY_REPO1_URL=\"&lt;Empty configuration repository URL&gt;\"\nREPOSITORY_REPO1_PROVIDER=\"&lt;github|bitbucket|gitlab|azure&gt;\"\nREPOSITORY_REPO1_ACCESS_TOKEN=\"&lt;Token with read/write access an empty Git repo that will be used for config storage&gt;\"\nREPOSITORY_REPO1_SOPS_KMS_ARN=\"&lt;AWS KMS key ARN&gt;\"\n\nREPOSITORY_REPO2_URL=\"&lt;Empty configuration repository URL&gt;\"\nREPOSITORY_REPO2_PROVIDER=\"&lt;github|bitbucket|gitlab|azure&gt;\"\nREPOSITORY_REPO2_ACCESS_TOKEN=\"&lt;Token with read/write access an empty Git repo that will be used for config storage&gt;\"\nREPOSITORY_REPO2_SOPS_AZURE_KV=\"&lt;Key URL. i.e. https://&lt;Vault name&gt;.vault.azure.net/keys/&lt;key name&gt;/&lt;string&gt;\"\n\nREPOSITORY_REPO3_URL=\"&lt;Empty configuration repository URL&gt;\"\nREPOSITORY_REPO3_PROVIDER=\"&lt;github|bitbucket|gitlab|azure&gt;\"\nREPOSITORY_REPO3_ACCESS_TOKEN=\"&lt;Token with read/write access an empty Git repo that will be used for config storage&gt;\"\nREPOSITORY_REPO3_SOPS_GCP_KMS=projects/&lt;project&gt;/locations/global/keyRings/&lt;keyring&gt;/cryptoKeys/&lt;key name&gt;\n</code></pre>"},{"location":"installation/server/#where-next","title":"Where Next?","text":"<p>Install and setup the CTO CLI to interact with the ECS server by following instructions here.</p>"},{"location":"schema_validation/","title":"Configuration Build Schema Verification","text":""},{"location":"schema_validation/#overview","title":"Overview","text":"<p>It is possible to create a JSON schema validation file called <code>__schemas.yaml</code> alongside any <code>__strategies.yaml</code> file and the schema will be used to validate output from the strategy. </p> <p>You can either write this schema file yourself, or you can use the ECS AI to generate it for you automatically based on the build output for the particular strategy and path. </p> <p>As an example, the following build output that uses the strategy <code>generate_ec2s</code>can be validated by using the <code>__schemas.yaml</code> file that follows.</p> <pre><code>team-1:                                                                                \n  ec2:                                                                                 \n    server-1:                                                                          \n      ami: ami-123456789                                                               \n      disk_size: 300                                                                   \n      instance_profile: instance-profile-1                                             \n      instance_type: t2.medium                                                         \n      tags:                                                                            \n        terraform: true                                                                \n      user_data: null                                                                  \n      vpc_name: default                                                                \n    server-2:                                                                          \n      ami: ami-123456789                                                               \n      disk_size: 800                                                                   \n      instance_profile: instance-profile-1                                             \n      instance_type: t2.medium                                                         \n      tags:                                                                            \n        terraform: true                                                                \n      user_data: null                                                                  \n      vpc_name: default                                                                \nteam-2:                                                                                \n  ec2:                                                                                 \n    server-1:                                                                          \n      ami: ami-123456789                                                               \n      disk_size: 1400                                                                  \n      instance_profile: instance-profile-1                                             \n      instance_type: t2.medium                                                         \n      tags:                                                                            \n        terraform: true                                                                \n      user_data: null                                                                  \n      vpc_name: default                                                                \n    server-2:                                                                          \n      ami: ami-123456789                                                               \n      disk_size: 1800                                                                  \n      instance_profile: instance-profile-1                                             \n      instance_type: t2.medium                                                         \n      tags:                                                                            \n        terraform: true                                                                \n      user_data: null                                                                  \n      vpc_name: default  \n</code></pre> <p><code>__schemas.yaml</code></p> <pre><code>---\nschemas:\n  generate_ec2s:\n    $schema: \"http://json-schema.org/draft-07/schema#\"\n    title: \"Team EC2 Instances Configuration\"\n    type: \"object\"\n    patternProperties:\n      \"^team-\\\\d+$\":\n        type: \"object\"\n        properties:\n          ec2:\n            type: \"object\"\n            patternProperties:\n              \"^server-\\\\d+$\":\n                type: \"object\"\n                properties:\n                  ami:\n                    type: \"string\"\n                    description: \"AMI ID\"\n                  disk_size:\n                    type: \"integer\"\n                    description: \"Size of the disk in GB\"\n                  instance_profile:\n                    type: \"string\"\n                    description: \"Instance profile name\"\n                  instance_type:\n                    type: \"string\"\n                    description: \"Type of the instance\"\n                  tags:\n                    type: \"object\"\n                    properties:\n                      terraform:\n                        type: \"boolean\"\n                        description: \"Terraform tag\"\n                    required:\n                      - \"terraform\"\n                    additionalProperties: false\n                  user_data:\n                    type:\n                      - \"string\"\n                      - \"null\"\n                    description: \"User data script\"\n                  vpc_name:\n                    type: \"string\"\n                    description: \"Name of the VPC\"\n                required:\n                  - \"ami\"\n                  - \"disk_size\"\n                  - \"instance_profile\"\n                  - \"instance_type\"\n                  - \"tags\"\n                  - \"user_data\"\n                  - \"vpc_name\"\n                additionalProperties: false\n        required:\n          - \"ec2\"\n        additionalProperties: false\n    additionalProperties: false\n</code></pre>"},{"location":"schema_validation/#ai-generated-schemas","title":"AI Generated Schemas","text":"<p>If ECS AI is licensed and turned on for your ECS Server instance, you can use the following commands to generate and write schemas for any build output:</p>"},{"location":"schema_validation/#use-ai-to-generate-schema","title":"Use AI to Generate Schema","text":"<p><code>cto ecs config generate-schema --path &lt;path to your config&gt; --strategy_name &lt;strategy name&gt;</code></p>"},{"location":"schema_validation/#use-ai-to-generate-and-write-schema","title":"Use AI to Generate and Write Schema","text":"<p><code>cto ecs config generate-schema --write --path &lt;path to your config&gt; --strategy_name &lt;strategy name&gt;</code></p>"},{"location":"schema_validation/#manual-schema-creation-and-editing","title":"Manual Schema Creation and Editing","text":"<p>To write your own schemas or to understand the schema language, see json-schema.org</p>"},{"location":"schema_validation/#where-next","title":"Where Next?","text":"<p>Check out Secret Management here</p>"},{"location":"schema_validation/pkl/","title":"Configuration Build Schema Validation","text":""},{"location":"schema_validation/pkl/#overview","title":"Overview","text":"<p>For Pkl outputs of type YAML or JSON it is possible to create a JSON schema validation file called <code>__schemas.yaml</code> alongside any <code>__strategies.yaml</code> file and the schema will be used to validate output from the Pkl build. When a schema is in place, any changes to the configuration need to create output of the same object structure, if they don't, the build will fail. This makes debugging pipeline failures a lot easier as ECS will gracefully fail the pipeline with a meaningful error informing you what caused the failure. </p> <p>You can either write this schema file yourself, or you can use the ECS AI to generate it for you automatically based on the build output for the particular strategy and path. </p> <p>Using the config examples in the getting started repo, the command <code>cto ecs config generate-schema --path config-examples/example-7/birds.pkl</code> will create the output below.</p> <pre><code>bird:                                                                                          \n  name: Pigeon                                                                                 \n  diet: Seeds                                                                                  \n  taxonomy:                                                                                    \n    kingdom: Animalia                                                                          \n    clade: Dinosauria                                                                          \n    order: Columbiformes                                                                       \nparrot:                                                                                        \n  name: Parrot                                                                                 \n  diet: ss                                                                                     \n  taxonomy:                                                                                    \n    kingdom: Animalia                                                                          \n    clade: Dinosauria                                                                          \n    order: Psittaciformes  \n</code></pre> <p>Use ECS AI to generate a schema: </p> <p><code>cto ecs config generate-schema --path config-examples/example-7/birds.pkl --write</code></p> <p>This command generates the following file:</p> <p><code>__schemas.yaml</code></p> <pre><code>---\nschemas:\n  config-examples/example-7/birds.pkl:\n    additionalProperties: false\n    patternProperties:\n      .*:\n        additionalProperties: false\n        properties:\n          diet:\n            type: string\n          name:\n            type: string\n          taxonomy:\n            additionalProperties: false\n            properties:\n              clade:\n                type: string\n              kingdom:\n                type: string\n              order:\n                type: string\n            required:\n            - kingdom\n            - clade\n            - order\n            type: object\n        required:\n        - name\n        - diet\n        - taxonomy\n        type: object\n    type: object\n</code></pre>"},{"location":"schema_validation/pkl/#ai-generated-schemas","title":"AI Generated Schemas","text":"<p>ECS AI needs to be licensed and turned on for your ECS Server instance, you can use the following commands to generate and write schemas for any build output:</p>"},{"location":"schema_validation/pkl/#use-ai-to-generate-schema","title":"Use AI to Generate Schema","text":"<p><code>cto ecs config generate-schema --path &lt;path to Pkl file&gt;</code></p>"},{"location":"schema_validation/pkl/#use-ai-to-generate-and-write-schema","title":"Use AI to Generate and Write Schema","text":"<p><code>cto ecs config generate-schema --write --path &lt;path Pkl file&gt;</code></p>"},{"location":"schema_validation/pkl/#see-it-in-action","title":"See it in Action","text":""},{"location":"schema_validation/pkl/#manual-schema-creation-and-editing","title":"Manual Schema Creation and Editing","text":"<p>To write your own schemas or to understand the schema language, see json-schema.org</p>"},{"location":"schema_validation/pkl/#where-next","title":"Where Next?","text":"<p>Check out Secret Management here</p>"},{"location":"secret_management/","title":"Secret Management","text":""},{"location":"secret_management/#overview","title":"Overview","text":"<p>It is possible to store secrets in ECS config and it is perfectly safe to do so. Secrets are encrypted using Mozilla SOPS and use an encryption key that resides in either Azure, AWS or GCP, or if you're using ECS Cloud, you have the option of using a key that is generated specifically for your account.</p> <p>A user has to have <code>read-secrets</code> privilege in order to view secrets, and if they have <code>read-secrets</code> privilege, they need access to the config path where your secrets reside. Using this mechanism it's possible to divide up your config so only a specific user or team can access secrets in that path.</p> <p>Typically only pipeline service accounts need access to be able to decrypt secrets.</p>"},{"location":"secret_management/#add-a-secret-to-config","title":"Add a Secret to Config","text":"<p>To add a secret to config, all you need to do is specify the field name of the secret with <code>_ecs_secret</code> as a suffix. As an example:</p> <pre><code>my-config:\n    secret: my-secret\n</code></pre> <p>will not encrypt your secret</p> <pre><code>my-config:\n    secret_ecs_secret: my-secret\n</code></pre> <p>When you push the config to the server, the fields secret value will have been encrpyted:</p> <pre><code>my-config:\n    secret_ecs_secret: ENC[AES256_GCM,data:Ev22+cln/Bn1,iv:QZejNi/1Nb64mtXkU4r4ptoFO1CweB0rhfMP+1EjDRk=,tag:JHaI+jp02adFryYixonBiQ==,type:str]\nsops:\n    kms:\n        - arn: arn:aws:kms:eu-west-1:123456789012:key/1234-1234-1234-1234\n          created_at: \"2024-02-30T12:51:51Z\"\n          enc: &lt;encrypted value&gt;\n          aws_profile: \"\"\n    gcp_kms: []\n    azure_kv: []\n    hc_vault: []\n    age: []\n    lastmodified: \"2024-02-30T12:51:51Z\"\n    mac: &lt;encrypted value&gt;\n    pgp: []\n    encrypted_suffix: _ecs_secret\n    version: 3.8.1\n</code></pre>"},{"location":"secret_management/#control-who-can-decrpyt-secrets","title":"Control Who Can Decrpyt Secrets","text":"<p>Only users with <code>read-secrets</code> can decrypt secrets. To create a user with this permission:</p> <p><code>cto ecs users create --username &lt;username&gt; --given-name &lt;name&gt; --family-name &lt;name&gt; --read-secrets</code></p>"},{"location":"secret_management/#output-with-secret-decryption","title":"Output With Secret Decryption","text":"<p>In your pipelines, you will want to decrypt any secrets using the command below:</p> <p><code>cto ecs config build --path &lt;path&gt; --show-secrets</code></p>"},{"location":"secret_management/#where-next","title":"Where Next?","text":"<p>Check out  Drift Detection here</p>"},{"location":"web_hooks/","title":"Webhooks","text":""},{"location":"web_hooks/#overview","title":"Overview","text":"<p>When a config change is made, it is likely that a pipeline needs to be triggered to reflect the change. ECS webhooks make this possible in much the same way as Github webhooks. </p> <p>ECS currently has support for 5 webhook types:</p> <ul> <li>Github actions<ul> <li>Runs any workflow with configurable parameters</li> </ul> </li> <li>Bitbucket runners<ul> <li>Runs any pipeline with configurable parameters</li> </ul> </li> <li>Gitlab<ul> <li>Runs any workflow with configurable parameters</li> </ul> </li> <li>Jenkins<ul> <li>Triggers any Jenkins job with configurable parameters</li> </ul> </li> <li>Custom<ul> <li>Trigger any pipeline via API call. Specify your own endpoint and payload</li> </ul> </li> </ul>"},{"location":"web_hooks/#configuring-webhooks","title":"Configuring Webhooks","text":"<p>Webhooks are configured for a config path by adding a __webhooks.yaml file to that path and specifying glob patters of files that if changed, will trigger the webhook. When the webhook runs, it should call <code>cto ecs config build</code> with the appropriate parameters to output the configuration to the pipeline.</p> <p>Any number and conbination of webhook types can be configured per path.</p> <p>On failure of a webhook, all listed email addresses under <code>notifications</code> are notified.</p> <p>Examples of the 5 types of webhooks are provided below:</p>"},{"location":"web_hooks/#github","title":"Github","text":"<p>An example Github webhook configuration is shown below:</p> <p>__webhooks.yaml <pre><code>webhooks:\n  test_webhook_github:\n    notification_emails: \n      - &lt;notification email address&gt;\n    file_pattern: \"*.yaml\"\n    webhook_type: github\n    repo_name: webservices\n    org_name: Cloud-Technology-Office\n    workflow_file: development.yaml\n    ref_name: main\n    token: $token\n    inputs:\n      env: development\n    variables:\n      token:\n        file_path:  webhook_tokens.yaml\n        key: github_token\n</code></pre></p> <p>In this example, the <code>development.yaml</code> workflow is triggered in repo <code>webservices</code> branch <code>main</code>. The workflow receives all input variables under <code>inputs</code> with the webhook being triggered using an encrypted authentication token provided in <code>webhook_tokens.yaml</code>. An example of the token file is shown below:</p> <p>webhook_tokens.yaml <pre><code>github_token_ecs_secret: &lt;your Github token&gt;\n</code></pre></p> <p>The tokens file can have any name you require, simple reference it in the <code>__webhooks.yaml</code> file. When this file is pushed to ECS using <code>cto ecs config push</code> it is encrypted. See secret management for more details on encrypting secrets in ECS.</p>"},{"location":"web_hooks/#gitlab","title":"Gitlab","text":"<p>An example Gitlab webhook configuration is shown below:</p> <p>__webhooks.yaml <pre><code>webhooks:\n  test_webhook_gitlab:\n    notification_emails: \n      - &lt;notification email address&gt;\n    webhook_type: gitlab\n    file_pattern: \"*.yaml\"\n    project_id: '1234567'\n    token: $token\n    ref_name: main\n    gitlab_vars:\n      my_var: test\n      my_var2: test\n      my_var3: test\n    token: $token\n    variables:\n      token:\n        file_path:  token.yaml\n        key: gitlab_token\n</code></pre></p> <p>In this example, the job is triggered in project <code>1234567</code> branch <code>main</code>. The workflow receives all input variables under <code>gitlab_vars</code> with the webhook being triggered using an encrypted authentication token provided in <code>webhook_tokens.yaml</code>. See example webhook_tokens.yaml in the Github example.</p>"},{"location":"web_hooks/#bitbucket","title":"Bitbucket","text":"<p>An example Bitbucket webhook configuration is shown below:</p> <p>__webhooks.yaml <pre><code>webhooks:\n  test_webhook_bitbucket:\n    notification_emails: \n        - &lt;notification email address&gt;\n    webhook_type: bitbucket\n    file_pattern: \"*.yaml\"\n    token: $token\n    custom_pipeline_name: default\n    workspace: test-workspace\n    repo_slug: webservices\n    ref_name: master\n    bitbucket_vars:\n      - key: \"var1key\"\n        value: \"var1value\"\n        secured: true    \n    variables:\n      token:\n        file_path:  token.yaml\n        key: gitlab_token\n</code></pre></p> <p>In this example, the job is triggered in workspace <code>test-workspace</code>, repo <code>webservices</code> branch <code>master</code>. The workflow receives all input variables under <code>bitbucket_vars</code> with the webhook being triggered using an encrypted authentication token provided in <code>webhook_tokens.yaml</code>. See example webhook_tokens.yaml in the Github example.</p>"},{"location":"web_hooks/#jenkins","title":"Jenkins","text":"<p>To use Jenkins webhooks, install the Jenkins plugin Generic webhook trigger</p> <p>An example Jenkins webhook configuration is shown below:</p> <p>__webhooks.yaml <pre><code>webhooks:\n  test_webhook_jenkins:\n    token: $token\n    notification_emails: \n        - &lt;notification email address&gt;\n    file_pattern: \"*.yaml\"\n    url: &lt;Jenkins server URL&gt;\n    webhook_type: jenkins\n    token: $jenkins_token\n    params:\n      env: development\n      other_param: anything\n    variables:\n      token:\n        file_path:  webhook_tokens.yaml\n        key: jenkins_token\n</code></pre></p> <p>In this example, the Jenkins job referenced by the token is triggered. The job receives all parameters under <code>params</code> with the webhook being triggered using an encrypted job token provided in <code>webhook_tokens.yaml</code>. See example webhook_tokens.yaml in the Github example.</p>"},{"location":"web_hooks/#custom","title":"Custom","text":"<p>Using custom webhooks, any API can be called:</p> <p>__webhooks.yaml <pre><code>webhooks:\n  test_webhook_custom:\n    token: $token\n    notification_emails: \n      - &lt;notification email address&gt;\n    webhook_type: custom\n    file_pattern: \"*.yaml\"\n    url: &lt;your endpoint URL&gt;\n    method: POST\n    headers:\n      Authorization: Bearer $token\n      Content-Type: \"application/json\"\n    body:\n      var1: value1\n      var2: value2\n      var3: value3\n    variables:\n      token:\n        file_path:  webhook_tokens.yaml\n        key: custom_webhook_token\n</code></pre></p> <p>In this example, the API referenced in <code>url</code> is called using the method specified in <code>method</code>. The API receives payload specified under <code>payload</code> with the API token being provided by an encrypted password token provided in <code>webhook_tokens.yaml</code>. See example webhook_tokens.yaml in the Github example.</p>"}]}